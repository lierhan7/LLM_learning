batch_size: 8
dataset_config: mrpc
dataset_name: glue
eval_steps: 500
eval_strategy: steps
fp16: false
gradient_accumulation_steps: 1
learning_rate: 5.0e-05
logging_dir: ./logs
logging_steps: 100
max_length: 512
model_name: bert-base-uncased
num_epochs: 3
num_labels: 2
output_dir: ./results
save_model: true
save_total_limit: 2
seed: 42
warmup_steps: 0
weight_decay: 0.01
