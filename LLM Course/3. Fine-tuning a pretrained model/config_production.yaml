batch_size: 16
dataset_config: mrpc
dataset_name: glue
eval_steps: 200
eval_strategy: steps
fp16: true
gradient_accumulation_steps: 1
learning_rate: 2.0e-05
logging_dir: ./logs
logging_steps: 100
max_length: 512
model_name: bert-base-uncased
num_epochs: 5
num_labels: 2
output_dir: ./production_results
save_model: true
save_total_limit: 2
seed: 42
warmup_steps: 100
weight_decay: 0.01
