# å¿«é€Ÿå…¥é—¨æŒ‡å— ğŸš€

## 1. ç¯å¢ƒå‡†å¤‡ (2åˆ†é’Ÿ)

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æ¿€æ´»condaç¯å¢ƒ (å¦‚æœä½¿ç”¨conda)
conda activate your_env_name
```

## 2. ç«‹å³å¼€å§‹è®­ç»ƒ (1åˆ†é’Ÿ)

### å¿«é€Ÿæµ‹è¯• âš¡
```bash
python run_training.py --template quick_test
```
*ä½¿ç”¨DistilBERTåœ¨bc2gm_corpusæ•°æ®é›†ä¸Šè¿›è¡Œ1è½®å¿«é€Ÿè®­ç»ƒ*

### ç”Ÿäº§ç¯å¢ƒè®­ç»ƒ ğŸ­
```bash
python run_training.py --template production --output_dir ./my_model
```
*ä½¿ç”¨BERT-Largeè¿›è¡Œå®Œæ•´çš„5è½®è®­ç»ƒ*

### è‡ªå®šä¹‰è®­ç»ƒ ğŸ¯
```bash
python run_training.py \
  --model_name bert-base-cased \
  --dataset_name bc2gm_corpus \
  --num_epochs 3 \
  --batch_size 16 \
  --learning_rate 2e-5 \
  --output_dir ./custom_model
```

## 3. æŸ¥çœ‹ç»“æœ ğŸ“Š

è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥è¾“å‡ºç›®å½•ï¼š
- `results.json`: è¯„ä¼°æŒ‡æ ‡
- `predictions.txt`: é¢„æµ‹ç»“æœ
- `training.log`: è®­ç»ƒæ—¥å¿—
- `pytorch_model.bin`: è®­ç»ƒå¥½çš„æ¨¡å‹

## 4. å¸¸ç”¨å‘½ä»¤ç»„åˆ ğŸ’¡

### è°ƒè¯•è®­ç»ƒ
```bash
python run_training.py --template quick_test --num_epochs 1 --batch_size 4
```

### GPUå†…å­˜ä¼˜åŒ–
```bash
python run_training.py --template production --fp16 --gradient_accumulation_steps 2
```

### ä½¿ç”¨æœ¬åœ°æ•°æ®
```bash
python run_training.py \
  --train_file ./data/train.json \
  --validation_file ./data/dev.json \
  --model_name bert-base-cased
```

### å®Œæ•´å®éªŒè®¾ç½®
```bash
python run_training.py \
  --template production \
  --experiment_name "my_ner_exp_v1" \
  --description "Testing BERT-Large on biomedical data" \
  --output_dir ./experiments/exp_v1 \
  --fp16 \
  --early_stopping_patience 3
```

## éœ€è¦å¸®åŠ©ï¼Ÿ ğŸ†˜

- æŸ¥çœ‹å®Œæ•´æ–‡æ¡£: [README.md](README.md)
- æ£€æŸ¥æ•°æ®é›†æ ¼å¼: `python check_dataset.py`
- æŸ¥çœ‹æ‰€æœ‰å‚æ•°: `python run_training.py --help`

---
**30ç§’å¼€å§‹è®­ç»ƒï¼Œ10åˆ†é’Ÿå¾—åˆ°ç»“æœï¼** â°
