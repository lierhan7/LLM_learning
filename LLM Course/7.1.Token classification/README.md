# Tokenåˆ†ç±»è®­ç»ƒæ¡†æ¶

ä¸€ä¸ªåŠŸèƒ½å®Œæ•´ã€ç»“æ„æ¸…æ™°çš„ä¸“ä¸šçº§Tokenåˆ†ç±»è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒå‘½åå®ä½“è¯†åˆ«(NER)ã€è¯æ€§æ ‡æ³¨(POS)ç­‰Tokençº§åˆ«çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚

## ğŸŒŸ ç‰¹æ€§

- **æ¨¡å—åŒ–è®¾è®¡**: æ¸…æ™°çš„ä»£ç æ¶æ„ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
- **é…ç½®ç®¡ç†**: æ”¯æŒYAMLé…ç½®æ–‡ä»¶å’Œé¢„å®šä¹‰æ¨¡æ¿
- **å¤šæ•°æ®é›†æ”¯æŒ**: æ”¯æŒHugging Faceæ•°æ®é›†å’Œæœ¬åœ°æ–‡ä»¶
- **çµæ´»çš„è®­ç»ƒé…ç½®**: æ”¯æŒæ··åˆç²¾åº¦ã€æ—©åœã€å­¦ä¹ ç‡è°ƒåº¦ç­‰
- **è¯¦ç»†çš„è¯„ä¼°åˆ†æ**: æä¾›F1ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ç­‰å¤šç§è¯„ä¼°æŒ‡æ ‡
- **é”™è¯¯åˆ†æ**: è‡ªåŠ¨åˆ†æé¢„æµ‹é”™è¯¯ç±»å‹å’ŒåŸå› 
- **å‘½ä»¤è¡Œæ¥å£**: å®Œæ•´çš„CLIæ”¯æŒï¼Œæ–¹ä¾¿æ‰¹å¤„ç†å’Œè„šæœ¬åŒ–
- **GPUåŠ é€Ÿ**: è‡ªåŠ¨æ£€æµ‹å’Œä½¿ç”¨å¯ç”¨çš„GPUè®¾å¤‡

## ğŸ“ é¡¹ç›®ç»“æ„

```
Token_Classification/
â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†æ¨¡å—
â”œâ”€â”€ data_processor.py      # æ•°æ®å¤„ç†æ¨¡å—
â”œâ”€â”€ model_manager.py       # æ¨¡å‹ç®¡ç†æ¨¡å—
â”œâ”€â”€ evaluator.py           # è¯„ä¼°æ¨¡å—
â”œâ”€â”€ trainer.py             # è®­ç»ƒæ¨¡å—
â”œâ”€â”€ run_training.py        # å‘½ä»¤è¡Œæ¥å£
â”œâ”€â”€ requirements.txt       # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ check_dataset.py       # æ•°æ®é›†æ£€æŸ¥å·¥å…·
â””â”€â”€ README.md              # é¡¹ç›®æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿æ‚¨çš„ç¯å¢ƒä¸­å®‰è£…äº†Python 3.8+å’Œå¿…è¦çš„ä¾èµ–åŒ…ï¼š

```bash
pip install -r requirements.txt
```

### 2. å¿«é€Ÿæµ‹è¯•

ä½¿ç”¨é¢„å®šä¹‰çš„å¿«é€Ÿæµ‹è¯•æ¨¡æ¿ï¼š

```bash
python run_training.py --template quick_test
```

### 3. ç”Ÿäº§ç¯å¢ƒè®­ç»ƒ

ä½¿ç”¨ç”Ÿäº§ç¯å¢ƒé…ç½®ï¼š

```bash
python run_training.py --template production --output_dir ./production_model
```

### 4. è‡ªå®šä¹‰è®­ç»ƒ

æŒ‡å®šè‡ªå®šä¹‰å‚æ•°ï¼š

```bash
python run_training.py --model_name bert-base-cased --num_epochs 5 --learning_rate 2e-5 --batch_size 16
```

## ğŸ“– è¯¦ç»†ä½¿ç”¨æŒ‡å—

### é…ç½®æ¨¡æ¿

æ¡†æ¶æä¾›ä¸‰ç§é¢„å®šä¹‰é…ç½®æ¨¡æ¿ï¼š

1. **quick_test**: å¿«é€Ÿæµ‹è¯•é…ç½®
   - æ¨¡å‹: DistilBERT
   - è®­ç»ƒè½®æ•°: 1
   - æ‰¹æ¬¡å¤§å°: 8
   - é€‚ç”¨äº: å¿«é€ŸéªŒè¯å’Œè°ƒè¯•

2. **production**: ç”Ÿäº§ç¯å¢ƒé…ç½®
   - æ¨¡å‹: BERT-Large
   - è®­ç»ƒè½®æ•°: 5
   - æ··åˆç²¾åº¦: å¯ç”¨
   - é€‚ç”¨äº: ç”Ÿäº§éƒ¨ç½²

3. **research**: ç ”ç©¶å®éªŒé…ç½®
   - æ¨¡å‹: RoBERTa-Large
   - è®­ç»ƒè½®æ•°: 10
   - è¯¦ç»†æ—¥å¿—: å¯ç”¨
   - é€‚ç”¨äº: å­¦æœ¯ç ”ç©¶

### å‘½ä»¤è¡Œå‚æ•°

#### åŸºç¡€å‚æ•°
- `--config`: æŒ‡å®šYAMLé…ç½®æ–‡ä»¶è·¯å¾„
- `--template`: ä½¿ç”¨é¢„å®šä¹‰æ¨¡æ¿ (quick_test|production|research)
- `--experiment_name`: å®éªŒåç§°
- `--description`: å®éªŒæè¿°

#### æ¨¡å‹å‚æ•°
- `--model_name`: é¢„è®­ç»ƒæ¨¡å‹åç§°æˆ–è·¯å¾„
- `--cache_dir`: æ¨¡å‹ç¼“å­˜ç›®å½•
- `--trust_remote_code`: æ˜¯å¦ä¿¡ä»»è¿œç¨‹ä»£ç 

#### æ•°æ®å‚æ•°
- `--dataset_name`: æ•°æ®é›†åç§° (å¦‚: bc2gm_corpus, conll2003)
- `--dataset_config`: æ•°æ®é›†é…ç½®
- `--train_file`: æœ¬åœ°è®­ç»ƒæ–‡ä»¶è·¯å¾„
- `--validation_file`: æœ¬åœ°éªŒè¯æ–‡ä»¶è·¯å¾„
- `--test_file`: æœ¬åœ°æµ‹è¯•æ–‡ä»¶è·¯å¾„
- `--max_length`: æœ€å¤§åºåˆ—é•¿åº¦
- `--label_all_tokens`: æ˜¯å¦æ ‡è®°æ‰€æœ‰å­è¯token

#### è®­ç»ƒå‚æ•°
- `--output_dir`: è¾“å‡ºç›®å½•
- `--num_epochs`: è®­ç»ƒè½®æ•°
- `--batch_size`: è®­ç»ƒæ‰¹æ¬¡å¤§å°
- `--eval_batch_size`: è¯„ä¼°æ‰¹æ¬¡å¤§å°
- `--learning_rate`: å­¦ä¹ ç‡
- `--weight_decay`: æƒé‡è¡°å‡
- `--warmup_ratio`: é¢„çƒ­æ¯”ä¾‹
- `--fp16`: å¯ç”¨FP16æ··åˆç²¾åº¦è®­ç»ƒ
- `--gradient_accumulation_steps`: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°

#### è¯„ä¼°å‚æ•°
- `--evaluation_strategy`: è¯„ä¼°ç­–ç•¥ (no|steps|epoch)
- `--eval_steps`: è¯„ä¼°é—´éš”æ­¥æ•°
- `--save_strategy`: ä¿å­˜ç­–ç•¥ (no|steps|epoch)
- `--save_steps`: ä¿å­˜é—´éš”æ­¥æ•°
- `--load_best_model_at_end`: è®­ç»ƒç»“æŸæ—¶åŠ è½½æœ€ä½³æ¨¡å‹
- `--early_stopping_patience`: æ—©åœè€å¿ƒå€¼

### é…ç½®æ–‡ä»¶ç¤ºä¾‹

åˆ›å»ºYAMLé…ç½®æ–‡ä»¶ `my_config.yaml`:

```yaml
experiment_name: "my_ner_experiment"
description: "è‡ªå®šä¹‰NERå®éªŒ"

model:
  model_name: "bert-base-cased"
  num_labels: null  # è‡ªåŠ¨æ¨æ–­

data:
  dataset_name: "bc2gm_corpus"
  dataset_config: "bc2gm_corpus"
  max_length: 512
  text_column_name: "tokens"
  label_column_name: "ner_tags"

training:
  output_dir: "./my_results"
  num_train_epochs: 3
  per_device_train_batch_size: 16
  learning_rate: 5e-5
  weight_decay: 0.01
  evaluation_strategy: "epoch"
  save_strategy: "epoch"
  load_best_model_at_end: true
  fp16: true

evaluation:
  metrics: ["seqeval"]
  output_predictions: true
  output_results: true
```

ä½¿ç”¨é…ç½®æ–‡ä»¶:
```bash
python run_training.py --config my_config.yaml
```

## ğŸ—ƒï¸ æ”¯æŒçš„æ•°æ®é›†

### Hugging Faceæ•°æ®é›†
- `bc2gm_corpus`: ç”Ÿç‰©åŒ»å­¦åŸºå› /è›‹ç™½è´¨å®ä½“è¯†åˆ«
- `conll2003`: CoNLL-2003 NERå…±äº«ä»»åŠ¡æ•°æ®é›†
- `wnut_17`: WNUT-2017æ–°å…´å®ä½“è¯†åˆ«
- å…¶ä»–å…¼å®¹çš„Tokenåˆ†ç±»æ•°æ®é›†

### æœ¬åœ°æ•°æ®é›†
æ”¯æŒä»¥ä¸‹æ ¼å¼çš„æœ¬åœ°æ–‡ä»¶ï¼š
- JSONæ ¼å¼: `{"tokens": [...], "ner_tags": [...]}`
- CSVæ ¼å¼: å¸¦æœ‰tokenså’Œlabelsåˆ—
- CoNLLæ ¼å¼: æ¯è¡Œä¸€ä¸ªtokenå’Œæ ‡ç­¾ï¼Œç©ºè¡Œåˆ†éš”å¥å­

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

æ¡†æ¶æä¾›å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡ï¼š

### åŸºç¡€æŒ‡æ ‡
- **F1åˆ†æ•°**: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
- **ç²¾ç¡®ç‡**: é¢„æµ‹æ­£ç¡®çš„å®ä½“å æ‰€æœ‰é¢„æµ‹å®ä½“çš„æ¯”ä¾‹
- **å¬å›ç‡**: é¢„æµ‹æ­£ç¡®çš„å®ä½“å æ‰€æœ‰çœŸå®å®ä½“çš„æ¯”ä¾‹
- **å‡†ç¡®ç‡**: Tokençº§åˆ«çš„åˆ†ç±»å‡†ç¡®ç‡

### è¯¦ç»†åˆ†æ
- **æŒ‰å®ä½“ç±»å‹çš„æŒ‡æ ‡**: æ¯ç§å®ä½“ç±»å‹çš„è¯¦ç»†è¯„ä¼°
- **æ··æ·†çŸ©é˜µ**: å¯è§†åŒ–åˆ†ç±»é”™è¯¯æƒ…å†µ
- **é”™è¯¯åˆ†æ**: è‡ªåŠ¨åˆ†ç±»é”™è¯¯ç±»å‹
  - False Positives: è¯¯æŠ¥
  - False Negatives: æ¼æŠ¥
  - Boundary Errors: è¾¹ç•Œé”™è¯¯
  - Type Errors: ç±»å‹é”™è¯¯

## ğŸ› ï¸ æ¨¡å—è¯´æ˜

### config.py
é…ç½®ç®¡ç†æ¨¡å—ï¼Œæä¾›ï¼š
- å±‚æ¬¡åŒ–é…ç½®ç»“æ„
- YAMLåºåˆ—åŒ–æ”¯æŒ
- é¢„å®šä¹‰é…ç½®æ¨¡æ¿
- å‘½ä»¤è¡Œå‚æ•°æ›´æ–°

### data_processor.py
æ•°æ®å¤„ç†æ¨¡å—ï¼Œè´Ÿè´£ï¼š
- æ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†
- Tokenå¯¹é½å’Œæ ‡ç­¾å¤„ç†
- æ•°æ®ç»Ÿè®¡å’Œå¯è§†åŒ–

### model_manager.py
æ¨¡å‹ç®¡ç†æ¨¡å—ï¼ŒåŒ…å«ï¼š
- é¢„è®­ç»ƒæ¨¡å‹åŠ è½½
- æ¨¡å‹é…ç½®å’Œä¼˜åŒ–
- å‚æ•°ç»Ÿè®¡å’Œå†…å­˜ç›‘æ§

### evaluator.py
è¯„ä¼°æ¨¡å—ï¼Œæä¾›ï¼š
- å¤šç§è¯„ä¼°æŒ‡æ ‡è®¡ç®—
- è¯¦ç»†çš„é”™è¯¯åˆ†æ
- ç»“æœå¯è§†åŒ–

### trainer.py
è®­ç»ƒæ¨¡å—ï¼Œæ˜¯æ¡†æ¶çš„æ ¸å¿ƒï¼š
- è®­ç»ƒæµç¨‹ç®¡ç†
- æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
- æ£€æŸ¥ç‚¹ä¿å­˜å’ŒåŠ è½½

### run_training.py
å‘½ä»¤è¡Œæ¥å£ï¼Œæä¾›ï¼š
- å®Œæ•´çš„CLIå‚æ•°æ”¯æŒ
- é…ç½®éªŒè¯å’Œé”™è¯¯æ£€æŸ¥
- å®éªŒç®¡ç†å’Œæ—¥å¿—è®°å½•

## ğŸ”§ é«˜çº§åŠŸèƒ½

### æ··åˆç²¾åº¦è®­ç»ƒ
å¯ç”¨FP16æˆ–BF16æ··åˆç²¾åº¦è®­ç»ƒä»¥åŠ é€Ÿè®­ç»ƒå’ŒèŠ‚çœå†…å­˜ï¼š

```bash
python run_training.py --fp16 --template production
```

### æ¢¯åº¦ç´¯ç§¯
å½“GPUå†…å­˜æœ‰é™æ—¶ï¼Œä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡ï¼š

```bash
python run_training.py --batch_size 8 --gradient_accumulation_steps 4
```

### æ—©åœæœºåˆ¶
è‡ªåŠ¨åœæ­¢è¿‡æ‹Ÿåˆçš„è®­ç»ƒï¼š

```bash
python run_training.py --early_stopping_patience 3
```

### å­¦ä¹ ç‡è°ƒåº¦
æ”¯æŒå¤šç§å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ï¼š

```bash
python run_training.py --lr_scheduler_type cosine --warmup_ratio 0.1
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§

### æ—¥å¿—æ–‡ä»¶
è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ `{output_dir}/training.log`ï¼ŒåŒ…å«ï¼š
- è®­ç»ƒè¿›åº¦å’ŒæŒ‡æ ‡
- æ¨¡å‹æ€§èƒ½å˜åŒ–
- é”™è¯¯å’Œè­¦å‘Šä¿¡æ¯

### ç»“æœæ–‡ä»¶
è®­ç»ƒç»“æœä¿å­˜åœ¨è¾“å‡ºç›®å½•ä¸­ï¼š
- `results.json`: è¯„ä¼°æŒ‡æ ‡
- `predictions.txt`: æ¨¡å‹é¢„æµ‹ç»“æœ
- `config.yaml`: å®é™…ä½¿ç”¨çš„é…ç½®
- `pytorch_model.bin`: è®­ç»ƒå¥½çš„æ¨¡å‹

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```bash
   # å‡å°æ‰¹æ¬¡å¤§å°
   python run_training.py --batch_size 4
   
   # ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
   python run_training.py --batch_size 4 --gradient_accumulation_steps 4
   ```

2. **æ•°æ®é›†åŠ è½½å¤±è´¥**
   ```bash
   # æ£€æŸ¥æ•°æ®é›†æ ¼å¼
   python check_dataset.py
   
   # æŒ‡å®šæ­£ç¡®çš„åˆ—å
   python run_training.py --dataset_name your_dataset --text_column_name tokens --label_column_name ner_tags
   ```

3. **æ¨¡å‹æ€§èƒ½ä¸ä½³**
   - å¢åŠ è®­ç»ƒè½®æ•°
   - è°ƒæ•´å­¦ä¹ ç‡
   - å°è¯•ä¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹
   - æ£€æŸ¥æ•°æ®è´¨é‡

### è°ƒè¯•æ¨¡å¼
ä½¿ç”¨å¿«é€Ÿæµ‹è¯•æ¨¡æ¿è¿›è¡Œè°ƒè¯•ï¼š

```bash
python run_training.py --template quick_test --num_epochs 1 --batch_size 2
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªæ¡†æ¶ï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®
1. å…‹éš†ä»“åº“
2. å®‰è£…ä¾èµ–: `pip install -r requirements.txt`
3. è¿è¡Œæµ‹è¯•: `python run_training.py --template quick_test`

### ä»£ç è§„èŒƒ
- éµå¾ªPEP 8ä»£ç é£æ ¼
- æ·»åŠ å¿…è¦çš„æ–‡æ¡£å­—ç¬¦ä¸²
- ç¼–å†™å•å…ƒæµ‹è¯•

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ï¼Œè¯¦è§LICENSEæ–‡ä»¶ã€‚

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- GitHub Issues: åœ¨é¡¹ç›®é¡µé¢æäº¤Issue
- Email: [æ‚¨çš„é‚®ç®±]

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®çš„æ”¯æŒï¼š
- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [Hugging Face Datasets](https://github.com/huggingface/datasets)
- [PyTorch](https://pytorch.org/)
- [scikit-learn](https://scikit-learn.org/)

---

**Happy Training! ğŸš€**
